#!/usr/bin/env python
# noinspection PyUnresolvedReferences

import datetime
import os
import shutil
import sys
from optparse import OptionParser, SUPPRESS_HELP
from os.path import isfile, join, isdir

from cluster_helper.cluster import cluster_view

import GeneAnnotation
import Utils.reference_data as ref
import targqc
import targqc.config as tc
from Utils import logger
from Utils.bam_bed_utils import extract_gene_names_and_filter_exons, verify_bam, verify_bed
from Utils.file_utils import adjust_path, safe_mkdir, verify_file, remove_quotes, file_exists, which
from Utils.logger import critical, err, info, warn, debug, is_local
from Utils.proc_args import read_samples, find_bams, find_fastq_pairs
from targqc import Sample
from targqc.fastq import align, downsample
from targqc.prep_bed import prepare_beds
from targqc.summarize import summarize_targqc

options = [
    (['--bam'], dict(dest='bam', help='path to the BAM file to analyse',)),
    (['-1'], dict(dest='l_fpath', help='fastq left reads, optional instead of BAM')),
    (['-2'], dict(dest='r_fpath', help='fastq right reads, optional instead of BAM')),
    (['--sample', '--name'], dict(dest='sample', help='Sample name (default is part of name of the first parameter prior to the first - or .',)),
    (['--bed', '--capture', '--amplicons'], dict(dest='bed', help='BED file with regions to analyse. If not specified, CDS across full genome will be analysed',)),
    (['-o', '--output-dir'], dict(
        dest='output_dir',
        metavar='DIR',
        help='Output directory (or directory name in case of bcbio final dir)',
        default=os.getcwd(),
     )),
    (['--refseq-bed', '--exons', '--exome', '--features'], dict(
        dest='features',
        help='BED file with real CDS/Exon/Gene/Transcript regions with annotations, to override '
             'GeneAnnotation/RefSeq/RefSeq_CDS_miRNA.all_features.{genome}.canon.bed',
     )),
    (['-g', '--genome'], dict(
        dest='genome',
        help='Genome build (hg19 or hg38), used to pick genome annotation BED file if not specified',
    )),
    (['--bwa-prefix'], dict(
        dest='bwa_prefix',
        help='Path to BWA index prefix to align if input is fastq',
     )),
    (['--padding'], dict(
        dest='padding',
        type='int',
        help='integer indicating the number of bases to extend each target region up and down-stream. '
             'Default is ' + str(tc.padding),
        default=tc.padding
     )),
    (['--downsample-to'], dict(
        dest='downsample_to',
        type='int',
        help='If input is fastq, optionally downsample reads to this number',
        default=tc.downsample_to,
     )),
    (['-t', '--nt', '--threads'], dict(
        dest='threads',
        type='int',
        help='Number of threads',
        default=tc.threads
     )),
    (['--reuse'], dict(
        dest='reuse_intermediate',
        help='reuse intermediate non-empty files in the work dir from previous run',
        action='store_true',
        default=tc.reuse_intermediate
     )),
    (['-s', '--scheduler'], dict(
        dest='scheduler',
        choices=["lsf", "sge", "torque", "slurm", "pbspro"],
        help="Scheduler to use for ipython parallel"
     )),
    (["-q", "--queue"], dict(
        dest='queue',
        help="Scheduler queue to run jobs on, for ipython parallel"
     )),
    (["-r", "--resources"], dict(
        dest='resources',
        help=("Cluster specific resources specifications. "
          "Can be specified multiple times.\n"
          "Supports SGE, Torque, LSF and SLURM "
          "parameters."),
        default=[],
        action="append")),

    ##############
    ## Extended: #
    (['--original-bed'], dict(
        dest='original_target_bed',
        help=SUPPRESS_HELP,
     )),
    (['--original-exons', '--original-features'], dict(
        dest='original_features_bed',
        help=SUPPRESS_HELP,  # original features genes bed file path (just for reporting)
     )),
    (['--features-no-genes', '--exons-no-genes'], dict(
        dest='features_no_genes',
        help=SUPPRESS_HELP,  # a BED file with real CDS/Exon regions with annotations, w/o Gene/Transcript records; provided if --no-prep-bed set
     )),
    (['--cds'], dict(
        dest='cds_bed_fpath',
        help=SUPPRESS_HELP,  # a BED file with real CDS regions in case if no --bed input provided, and if --no-prep-bed set
     )),
    (['--fai'], dict(
        dest='fai',
        help=SUPPRESS_HELP,  # Path to FAI file - to sort BAM and BED files, and to get chromosome lengths for proper padding BED files; optional
     )),
    # (['--reannotate'], dict(
    #     dest='reannotate',
    #     help='re-annotate BED file with gene names',
    #     action='store_true',
    #     default=True)
    #  ),
    (['--no-prep-bed'], dict(
        dest='prep_bed',
        help=SUPPRESS_HELP,
        default=True,
        action='store_false'
     )),
    (['-e', '--extended'], dict(
        dest='extended',
        action='store_true',
        default=False,
        help=SUPPRESS_HELP,  # 'extended - flagged regions and missed variants',
     )),
    (['--no-dedup'], dict(
        dest='no_dedup',
        action='store_true',
        help=SUPPRESS_HELP,
        default=not tc.dedup,
     )),
    (['--debug'], dict(
        dest='debug',
        action='store_true',
        default=tc.debug,
        help=SUPPRESS_HELP,
     )),
    (['--work-dir'], dict(dest='work_dir', metavar='DIR', help=SUPPRESS_HELP)),
    (['--log-dir'], dict(dest='log_dir', metavar='DIR', help=SUPPRESS_HELP)),
    # (['--project-name'], dict(dest='project_name', help=SUPPRESS_HELP)),
    (['--email'], dict(dest='email', help=SUPPRESS_HELP)),
]


def main(args):
    output_dir, work_dir, bam_by_sample, fastqs_by_sample, target_bed, prep_bed = process_opts()

    samples = []
    for sname, (l, r) in fastqs_by_sample.items():
        s = Sample(sname, join(output_dir, sname))
        s.l_fpath = l
        s.r_fpath = r
        samples.append(s)
    for sname, bam_fpath in bam_by_sample.items():
        s = Sample(sname, join(output_dir, sname), bam=bam_fpath)
        samples.append(s)

    samples.sort(key=lambda _s: _s.key_to_sort())

    if prep_bed:
        info()
        debug('*' * 70)
        info('Preparing input BED file')
        tc.features_bed_fpath, target_bed, seq2c_bed = prepare_beds(
            work_dir, tc.fai_fpath, tc.features_bed_fpath, target_bed, tc.cds_bed_fpath, reuse=tc.reuse_intermediate)

        tc.original_target_bed = tc.features_bed_fpath
        gene_keys_set, gene_keys_list, genes_not_in_refseq, target_bed, tc.features_bed_fpath = extract_gene_names_and_filter_exons(
            work_dir, target_bed, tc.features_bed_fpath, reuse=tc.reuse_intermediate)
    else:
        info('The BED file is ready, skipping preparing.')
        gene_keys_set, gene_keys_list, genes_not_in_refseq, _, _ = extract_gene_names_and_filter_exons(
            work_dir, target_bed, tc.features_bed_fpath, reuse=tc.reuse_intermediate)
    info('*' * 70)

    nodes = min(tc.threads, len(samples))
    tc.threads_one_sample = max(1, tc.threads/len(samples))
    if tc.scheduler:
        info('Running on' + (' test' if is_local() else '') + ' cluster (scheduler' + tc.scheduler + ', queue ' + tc.queue + ') '
             'using ' + str(nodes) + ' nodes, ' + str(tc.threads_one_sample) + ' thread per each sample')
        with cluster_view(scheduler=tc.scheduler, queue=tc.queue,
              num_jobs=nodes, cores_per_job=tc.threads_one_sample,
              extra_params={'run_local': is_local()}) as view:
            n = len(samples)
            # view.map(test_cluster, work_dir)
            view.map(proc_one_sample, [work_dir]*n, samples, [target_bed]*n, [gene_keys_list]*n, [genes_not_in_refseq]*n)
    else:
        info('Running locally, using ' + str(tc.threads) + ' threads')
        for s in samples:
            proc_one_sample(work_dir, s, target_bed, gene_keys_list, genes_not_in_refseq)

    if not tc.debug and work_dir and isdir(work_dir):
        shutil.rmtree(work_dir)

    info()
    info('*' * 70)
    info('Summarizing')
    summarize_targqc(tc.threads, output_dir, work_dir, samples, bed_fpath=target_bed, features_fpath=tc.features_bed_fpath)

    # info()
    # info('Summarizing: running MultiQC')
    # cmd = 'multiqc ' + output_dir + ('' if tc.reuse_intermediate else ' --force') + ' -v ' + ' '.join(s.dirpath for s in samples)
    # run(cmd)


def test_cluster(work_dir):
    print work_dir


def proc_one_sample(work_dir, sample, bed_fpath, gene_keys_list, genes_not_in_refseq):
    from os.path import join
    import targqc.config as tc
    from Utils.Region import build_gene_objects_list
    from Utils.file_utils import safe_mkdir, verify_file
    from Utils.logger import info
    from Utils.sambamba import index_bam
    from targqc.general_report import make_general_report
    from targqc.region_coverage import make_per_gene_report

    sample_work_dir = join(work_dir, sample.name)
    safe_mkdir(sample_work_dir)

    info()
    info('-' * 70)
    info('* Sample ' + sample.name + ' *')
    info()

    if not sample.bam and sample.l_fpath and sample.r_fpath:
        sample.bam = proc_fastq(
            sample.name, verify_file(sample.l_fpath), verify_file(sample.r_fpath),
            tc.bwa_prefix, tc.downsample_to, tc.dedup)
    info('Using alignment ' + sample.bam)
    index_bam(sample.bam)

    gene_by_name_and_chrom = build_gene_objects_list(sample.name, tc.features_bed_fpath, gene_keys_list)

    info('Making general report for ' + sample.name + ', saving into ' + sample.dirpath)
    general_report, avg_depth = make_general_report(sample_work_dir, sample, bed_fpath, gene_by_name_and_chrom)

    info()
    info('Making region-level report...')
    per_gene_report = make_per_gene_report(sample_work_dir, sample, bed_fpath, tc.features_bed_fpath,
                                           gene_by_name_and_chrom, avg_depth)
    info('')
    info('*' * 70)
    if general_report.txt_fpath and verify_file(general_report.txt_fpath):
        info('Summary report: ' + general_report.txt_fpath)
    if per_gene_report:
        if per_gene_report.txt_fpath and verify_file(per_gene_report.txt_fpath):
            info('All regions: ' + per_gene_report.txt_fpath + ' (' + str(len(per_gene_report.rows)) + ' regions)')


def set_up_dirs(output_dir=None, work_dir=None, log_dir=None):
    """ Creates output_dir, work_dir; sets up log
    """
    output_dir = adjust_path(output_dir or join(os.getcwd(), targqc.targqc_name))
    safe_mkdir(output_dir, 'output_dir')
    debug('Saving results into ' + output_dir)

    if not work_dir:
        work_dir_name = 'work'
        work_dir = join(output_dir, work_dir_name)
    safe_mkdir(work_dir, 'working directory')
    tc.work_dir = work_dir

    set_up_log(log_dir or work_dir)

    return output_dir, work_dir


def set_up_log(log_dir):
    log_fname = targqc.targqc_name + '.log'
    log_fpath = join(log_dir, log_fname)

    if file_exists(log_fpath):
        timestamp = datetime.datetime.fromtimestamp(os.stat(log_fpath).st_mtime)
        mv_log_fpath = log_fpath + '.' + timestamp.strftime("%Y-%m-%d_%H-%M-%S")
        try:
            if isfile(mv_log_fpath):
                os.remove(mv_log_fpath)
            if not isfile(mv_log_fpath):
                os.rename(log_fpath, mv_log_fpath)
        except OSError:
            pass

    logger.log_fpath = log_fpath
    debug('Logging to ' + log_fpath)
    debug()


def process_opts():
    parser = OptionParser()
    for args, kwargs in options:
        parser.add_option(*args, **kwargs)
    opts, args = parser.parse_args()

    tc.debug = logger.is_debug = opts.debug

    output_dir, work_dir = set_up_dirs(opts.output_dir, opts.work_dir, opts.log_dir)
    debug(' '.join(sys.argv))
    debug()

    tc.threads = opts.threads
    tc.scheduler = opts.scheduler
    tc.queue = opts.queue
    tc.reuse_intermediate = opts.reuse_intermediate

    bam_by_sample = dict()
    fastqs_by_sample = dict()

    if opts.bam or opts.l_fpath:
        if opts.sample_name:
            sample_name = remove_quotes(opts.sample_name)
            if opts.bam:
                bam_by_sample[sample_name] = verify_bam(opts.bam, is_critical=True)
            elif opts.l_fpath:
                l_fpath = verify_bam(opts.l_fpath, is_critical=True)
                r_fpath = verify_bam(opts.l_fpath)
                fastqs_by_sample[sample_name] = l_fpath, r_fpath
        else:
            if opts.bam:
                bam_by_sample = find_bams(opts.bam)
            elif opts.l_fpath:
                fastqs_by_sample = find_fastq_pairs([opts.l_fpath, opts.r_fpath])
    else:
        fastqs_by_sample, bam_by_sample = read_samples(args)

    if fastqs_by_sample:
        if not opts.bwa_prefix:
            critical('--bwa-prefix is required when running from fastq')
        tc.bwa_prefix = verify_file(opts.bwa_prefix, is_critical=True)

    tc.downsample_to = opts.downsample_to
    tc.padding = opts.padding
    tc.genome = opts.genome
    tc.dedup = not opts.no_dedup

    if opts.features:
        tc.features_bed_fpath = verify_bed(opts.features, is_critical=True)
        tc.cds_bed_fpath = verify_bed(opts.cds_bed_fpath, is_critical=True)
    elif tc.genome:
        tc.features_bed_fpath = GeneAnnotation.get_all_features_canonical(tc.genome)
        tc.cds_bed_fpath = GeneAnnotation.get_cds(tc.genome)
        if not tc.features_bed_fpath or not tc.cds_bed_fpath:
            critical('Genome ' + tc.genome + ' is not supported. Supported: ' + ', '.join(GeneAnnotation.SUPPORTED_GENOMES))
    else:
        warn('Neither --refseq-bed nor --genome is specified, analysing without genomic features.')
    if opts.features_no_genes:
        tc.features_no_genes_bed = verify_bed(opts.features_no_genes, is_critical=True)
    tc.original_target_bed = opts.original_target_bed

    bed_fpath = None
    if opts.bed:
        bed_fpath = verify_file(opts.bed, is_critical=True)
        info('Using target BED file ' + bed_fpath)
    elif tc.features_bed_fpath:
        info('No input BED. Assuming whole genome. For region-based reports, analysing RefSeq CDS.')

    if opts.fai:
        tc.fai_fpath = opts.fai
    elif tc.genome:
        tc.fai_fpath = ref.get_fai(tc.genome)
    else:
        err('Cannot analyse BED files without --fai or --genome specified')

    return output_dir, work_dir, bam_by_sample, fastqs_by_sample, bed_fpath, opts.prep_bed


def proc_fastq(work_dir, sample_name, l_fpath, r_fpath, bwa_prefix, downsample_to, dedup=True):
    if downsample_to:
        info('Downsampling the reads to ' + str(downsample_to))
        l_fpath, r_fpath = downsample(work_dir, sample_name, work_dir, l_fpath, r_fpath, downsample_to, suffix='subset')

    sambamba = which('sambamba')
    bwa = which('bwa')
    seqtk = which('seqtk')
    samblaster = which('samblaster')
    if not (sambamba and bwa and seqtk and samblaster):
        critical('sambamba, BWA, seqtk and samblaster are required to align BAM')
    info()
    info('Aligning reads to the reference')
    bam_fpath = align(work_dir, sample_name, l_fpath, r_fpath, sambamba, bwa, seqtk, samblaster, bwa_prefix, dedup)
    bam_fpath = verify_bam(bam_fpath)
    if not bam_fpath:
        critical('Sample ' + sample_name + ' was not aligned successfully.')
    return bam_fpath


if __name__ == '__main__':
    main(sys.argv)


