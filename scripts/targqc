#!/usr/bin/env python
# noinspection PyUnresolvedReferences

import datetime
import os
import shutil
import sys
from optparse import OptionParser, SUPPRESS_HELP
from os.path import isfile, join, isdir

from cluster_helper.cluster import cluster_view

import GeneAnnotation
import Utils.reference_data as ref
import targqc
import targqc.config as cfg
from Utils import logger
from Utils.bam_bed_utils import verify_bam, verify_bed
from Utils.file_utils import adjust_path, safe_mkdir, verify_file, remove_quotes, file_exists, which
from Utils.logger import critical, err, info, warn, debug, is_local
from Utils.proc_args import read_samples, find_bams, find_fastq_pairs
from Utils.sambamba import index_bam
from targqc import Sample
from targqc.Target import Target
from targqc.fastq import align, downsample
from targqc.parallel import ParallelCfg, parallel_view

from targqc.general_report import make_general_reports
from targqc.prep_bed import prepare_beds
from targqc.region_coverage import make_region_reports
from targqc.summarize import summarize_targqc

options = [
    (['--bam'], dict(dest='bam', help='path to the BAM file to analyse',)),
    (['-1'], dict(dest='l_fpath', help='fastq left reads, optional instead of BAM')),
    (['-2'], dict(dest='r_fpath', help='fastq right reads, optional instead of BAM')),
    (['--sample', '--name'], dict(dest='sample', help='Sample name (default is part of name of the first parameter prior to the first - or .',)),
    (['--bed', '--capture', '--amplicons'], dict(dest='bed', help='BED file with regions to analyse. If not specified, CDS across full genome will be analysed',)),
    (['-o', '--output-dir'], dict(
        dest='output_dir',
        metavar='DIR',
        help='Output directory (or directory name in case of bcbio final dir)',
        default=os.getcwd(),
     )),
    (['--refseq-bed', '--exons', '--exome', '--features'], dict(
        dest='features',
        help='BED file with real CDS/Exon/Gene/Transcript regions with annotations, to override '
             'GeneAnnotation/RefSeq/RefSeq_CDS_miRNA.all_features.{genome}.canon.bed',
     )),
    (['-g', '--genome'], dict(
        dest='genome',
        help='Genome build (hg19 or hg38), used to pick genome annotation BED file if not specified',
    )),
    (['--bwa-prefix'], dict(
        dest='bwa_prefix',
        help='Path to BWA index prefix to align if input is fastq',
     )),
    (['--padding'], dict(
        dest='padding',
        type='int',
        help='integer indicating the number of bases to extend each target region up and down-stream. '
             'Default is ' + str(cfg.padding),
        default=cfg.padding
     )),
    (['--downsample-to'], dict(
        dest='downsample_to',
        type='int',
        help='If input is fastq, optionally downsample reads to this number',
        default=cfg.downsample_to,
     )),
    (['-t', '--nt', '--threads'], dict(
        dest='threads',
        type='int',
        help='Number of threads'
     )),
    (['--reuse'], dict(
        dest='reuse_intermediate',
        help='reuse intermediate non-empty files in the work dir from previous run',
        action='store_true',
        default=cfg.reuse_intermediate
     )),
    (['-s', '--scheduler'], dict(
        dest='scheduler',
        choices=["lsf", "sge", "torque", "slurm", "pbspro"],
        help="Scheduler to use for ipython parallel"
     )),
    (["-q", "--queue"], dict(
        dest='queue',
        help="Scheduler queue to run jobs on, for ipython parallel"
     )),
    (["-r", "--resources"], dict(
        dest='resources',
        help=("Cluster specific resources specifications. "
          "Can be specified multiple times.\n"
          "Supports SGE, Torque, LSF and SLURM "
          "parameters."),
        default=[],
        action="append")),

    ##############
    ## Extended: #
    (['--original-bed'], dict(
        dest='original_target_bed',
        help=SUPPRESS_HELP,
     )),
    (['--original-exons', '--original-features'], dict(
        dest='original_features_bed',
        help=SUPPRESS_HELP,  # original features genes bed file path (just for reporting)
     )),
    (['--features-no-genes', '--exons-no-genes'], dict(
        dest='features_no_genes',
        help=SUPPRESS_HELP,  # a BED file with real CDS/Exon regions with annotations, w/o Gene/Transcript records; provided if --no-prep-bed set
     )),
    (['--cds'], dict(
        dest='cds_bed_fpath',
        help=SUPPRESS_HELP,  # a BED file with real CDS regions in case if no --bed input provided, and if --no-prep-bed set
     )),
    (['--fai'], dict(
        dest='fai',
        help=SUPPRESS_HELP,  # Path to FAI file - to sort BAM and BED files, and to get chromosome lengths for proper padding BED files; optional
     )),
    # (['--reannotate'], dict(
    #     dest='reannotate',
    #     help='re-annotate BED file with gene names',
    #     action='store_true',
    #     default=True)
    #  ),
    (['--no-prep-bed'], dict(
        dest='prep_bed',
        help=SUPPRESS_HELP,
        default=True,
        action='store_false'
     )),
    (['-e', '--extended'], dict(
        dest='extended',
        action='store_true',
        default=False,
        help=SUPPRESS_HELP,  # 'extended - flagged regions and missed variants',
     )),
    (['--no-dedup'], dict(
        dest='no_dedup',
        action='store_true',
        help=SUPPRESS_HELP,
        default=not cfg.dedup,
     )),
    (['--debug'], dict(
        dest='debug',
        action='store_true',
        default=cfg.debug,
        help=SUPPRESS_HELP,
     )),
    (['--work-dir'], dict(dest='work_dir', metavar='DIR', help=SUPPRESS_HELP)),
    (['--log-dir'], dict(dest='log_dir', metavar='DIR', help=SUPPRESS_HELP)),
    # (['--project-name'], dict(dest='project_name', help=SUPPRESS_HELP)),
    (['--email'], dict(dest='email', help=SUPPRESS_HELP)),
]


def _prep_samples(fastqs_by_sample, bam_by_sample, output_dir, work_dir):
    samples = []
    for sname, (l, r) in fastqs_by_sample.items():
        s = Sample(sname, join(output_dir, sname), join(work_dir, sname))
        s.l_fpath = l
        s.r_fpath = r
        samples.append(s)
    for sname, bam_fpath in bam_by_sample.items():
        s = Sample(sname, join(output_dir, sname), join(work_dir, sname), bam=bam_fpath)
        samples.append(s)
    samples.sort(key=lambda _s: _s.key_to_sort())
    for s in samples:
        safe_mkdir(s.work_dir)
        safe_mkdir(s.dirpath)
    return samples


# def _prep_beds(prep_bed, work_dir, target_bed):
#     target = None
#
#     if prep_bed:
#         info()
#         debug('*' * 70)
#         info('Preparing input BED file: sort, clean, cut, annotate')
#         cfg.features_bed_fpath, target_bed, seq2c_bed = prepare_beds(
#             work_dir, cfg.fai_fpath, cfg.features_bed_fpath, target_bed, cfg.cds_bed_fpath, reuse=cfg.reuse_intermediate)
#
#         if target_bed:
#             target, cfg.features_bed_fpath = extract_gene_names_and_filter_exons(
#                 work_dir, target_bed, cfg.features_bed_fpath, reuse=cfg.reuse_intermediate)
#     else:
#         info('The BED file is ready, skipping preparing.')
#         if target_bed:
#             target, _, _ = extract_gene_names_and_filter_exons(
#                 work_dir, target_bed, cfg.features_bed_fpath, reuse=cfg.reuse_intermediate)
#     info('*' * 70)
#     return target


def main(args):
    output_dir, work_dir, bam_by_sample, fastqs_by_sample, target_bed_fpath, prep_bed = process_opts()

    samples = _prep_samples(fastqs_by_sample, bam_by_sample, output_dir, work_dir)

    if target_bed_fpath:
        target = Target(target_bed_fpath)
        if prep_bed:
            info()
            debug('*' * 70)
            info('Preparing input BED file: sort, clean, cut, annotate')
            target_bed_fpath, cfg.features_bed_fpath = prepare_beds(
                    work_dir, cfg.fai_fpath, cfg.features_bed_fpath, target_bed_fpath, cfg.cds_bed_fpath, reuse=cfg.reuse_intermediate)
            target.bed_fpath = target_bed_fpath

        cfg.features_bed_fpath = \
            target.extract_gene_names_and_filter_exons(work_dir, cfg.features_bed_fpath, reuse=cfg.reuse_intermediate)
    else:
        target = Target(None)

    info()
    start_targqc(work_dir, samples, target)

    if not cfg.debug and work_dir and isdir(work_dir):
        shutil.rmtree(work_dir)
    info()
    info('*' * 70)
    info('Summarizing')
    summarize_targqc(cfg.parallel_cfg.threads, output_dir, work_dir, samples, bed_fpath=target_bed_fpath, features_fpath=cfg.features_bed_fpath)

    # info()
    # info('Summarizing: running MultiQC')
    # cmd = 'multiqc ' + output_dir + ('' if cfg.reuse_intermediate else ' --force') + ' -v ' + ' '.join(s.dirpath for s in samples)
    # run(cmd)


def start_targqc(work_dir, samples, target):
    fastq_samples = [s for s in samples if not s.bam and s.l_fpath and s.r_fpath]
    if fastq_samples:
        with parallel_view(len(fastq_samples), cfg.parallel_cfg) as view:
            proc_fastq(fastq_samples, view, work_dir, cfg.bwa_prefix, cfg.downsample_to, cfg.dedup)

    for s in samples:
        info(s.name + ': using alignment ' + s.bam)

    info()
    with parallel_view(len(samples), cfg.parallel_cfg) as view:
        info('Indexing BAMs...')
        view.run(index_bam, [[s.bam] for s in samples])

        info('Making general reports...')
        general_reports = make_general_reports(view, samples, target)

        info()
        info('Making region-level reports...')
        per_gene_reports = make_region_reports(view, work_dir, samples, target, cfg.features_bed_fpath)

    # for general_report, per_gene_report, sample in zip(general_reports, per_gene_reports, samples):
    #     info('')
    #     info('*' * 70)
    #     if general_report.txt_fpath and verify_file(general_report.txt_fpath):
    #         info('Summary report: ' + general_report.txt_fpath)
    #     if per_gene_report:
    #         path = per_gene_report if isinstance(per_gene_report, basestring) else per_gene_report.txt_fpath
    #         if path and verify_file(path):
    #             info('Region-based report: ' + path)


def set_up_dirs(output_dir=None, work_dir=None, log_dir=None):
    """ Creates output_dir, work_dir; sets up log
    """
    output_dir = adjust_path(output_dir or join(os.getcwd(), targqc.targqc_name))
    safe_mkdir(output_dir, 'output_dir')
    debug('Saving results into ' + output_dir)

    if not work_dir:
        work_dir_name = 'work'
        work_dir = join(output_dir, work_dir_name)
    safe_mkdir(work_dir, 'working directory')
    cfg.work_dir = work_dir

    set_up_log(log_dir or work_dir)

    return output_dir, work_dir


def set_up_log(log_dir):
    log_fname = targqc.targqc_name + '.log'
    log_fpath = join(log_dir, log_fname)

    if file_exists(log_fpath):
        timestamp = datetime.datetime.fromtimestamp(os.stat(log_fpath).st_mtime)
        mv_log_fpath = log_fpath + '.' + timestamp.strftime("%Y-%m-%d_%H-%M-%S")
        try:
            if isfile(mv_log_fpath):
                os.remove(mv_log_fpath)
            if not isfile(mv_log_fpath):
                os.rename(log_fpath, mv_log_fpath)
        except OSError:
            pass

    logger.log_fpath = log_fpath
    debug('Logging to ' + log_fpath)
    debug()


def process_opts():
    parser = OptionParser()
    for args, kwargs in options:
        parser.add_option(*args, **kwargs)
    opts, args = parser.parse_args()

    cfg.debug = logger.is_debug = opts.debug

    output_dir, work_dir = set_up_dirs(opts.output_dir, opts.work_dir, opts.log_dir)
    debug(' '.join(sys.argv))
    debug()

    cfg.parallel_cfg = ParallelCfg(opts.scheduler, opts.queue, opts.resources, opts.threads)

    cfg.reuse_intermediate = opts.reuse_intermediate

    bam_by_sample = dict()
    fastqs_by_sample = dict()

    if opts.bam or opts.l_fpath:
        if opts.sample_name:
            sample_name = remove_quotes(opts.sample_name)
            if opts.bam:
                bam_by_sample[sample_name] = verify_bam(opts.bam, is_critical=True)
            elif opts.l_fpath:
                l_fpath = verify_bam(opts.l_fpath, is_critical=True)
                r_fpath = verify_bam(opts.l_fpath)
                fastqs_by_sample[sample_name] = l_fpath, r_fpath
        else:
            if opts.bam:
                bam_by_sample = find_bams(opts.bam)
            elif opts.l_fpath:
                fastqs_by_sample = find_fastq_pairs([opts.l_fpath, opts.r_fpath])
    else:
        fastqs_by_sample, bam_by_sample = read_samples(args)

    if fastqs_by_sample:
        if not opts.bwa_prefix:
            critical('--bwa-prefix is required when running from fastq')
        cfg.bwa_prefix = verify_file(opts.bwa_prefix, is_critical=True)

    cfg.downsample_to = opts.downsample_to
    cfg.padding = opts.padding
    cfg.genome = opts.genome
    cfg.dedup = not opts.no_dedup

    if opts.features:
        cfg.features_bed_fpath = verify_bed(opts.features, is_critical=True)
        cfg.cds_bed_fpath = verify_bed(opts.cds_bed_fpath, is_critical=True)
    elif cfg.genome:
        cfg.features_bed_fpath = GeneAnnotation.get_all_features_canonical(cfg.genome)
        cfg.cds_bed_fpath = GeneAnnotation.get_cds(cfg.genome)
        if not cfg.features_bed_fpath or not cfg.cds_bed_fpath:
            critical('Genome ' + cfg.genome + ' is not supported. Supported: ' + ', '.join(GeneAnnotation.SUPPORTED_GENOMES))
    else:
        warn('Neither --refseq-bed nor --genome is specified, analysing without genomic features.')
    if opts.features_no_genes:
        cfg.features_no_genes_bed = verify_bed(opts.features_no_genes, is_critical=True)
    cfg.original_target_bed = opts.original_target_bed

    bed_fpath = None
    if opts.bed:
        bed_fpath = verify_file(opts.bed, is_critical=True)
        info('Using target BED file ' + bed_fpath)
    elif cfg.features_bed_fpath:
        info('No input BED. Assuming whole genome. For region-based reports, analysing RefSeq CDS.')

    if opts.fai:
        cfg.fai_fpath = opts.fai
    elif cfg.genome:
        cfg.fai_fpath = ref.get_fai(cfg.genome)
    else:
        err('Cannot analyse BED files without --fai or --genome specified')

    return output_dir, work_dir, bam_by_sample, fastqs_by_sample, bed_fpath, opts.prep_bed


def proc_fastq(samples, parall_view, work_dir, bwa_prefix, downsample_to, dedup=True):
    if downsample_to:
        info('Downsampling the reads to ' + str(downsample_to))
        fastq_pairs = parall_view.run(downsample,
            [[s.work_dir, s.name, s.work_dir, s.l_fpath, s.r_fpath, downsample_to, 'subset'] for s in samples])
        for s, (l_r, r_r) in zip(samples, fastq_pairs):
            s.l_fpath = l_r
            s.r_fpath = r_r

    sambamba = which('sambamba')
    bwa = which('bwa')
    seqtk = which('seqtk')
    samblaster = which('samblaster')
    if not (sambamba and bwa and seqtk and samblaster):
        critical('sambamba, BWA, seqtk and samblaster are required to align BAM')
    info()
    info('Aligning reads to the reference')
    bam_fpaths = parall_view.run(align,
        [[work_dir, s.name, s.l_fpath, s.r_fpath, sambamba, bwa, seqtk, samblaster, bwa_prefix, dedup]
         for s in samples])

    bam_fpaths = map(verify_bam, bam_fpaths)
    if len(bam_fpaths) < len(samples):
        critical('Some samples were not aligned successfully.')
    for bam, s in zip(bam_fpaths, samples):
        s.bam = bam


if __name__ == '__main__':
    main(sys.argv)


