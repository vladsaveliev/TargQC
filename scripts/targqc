#!/usr/bin/env python
# noinspection PyUnresolvedReferences


import datetime
import shutil
import sys
import os
from os.path import join, basename, abspath, dirname, pardir, isfile, join, basename, splitext, dirname, isdir
from optparse import OptionParser, SUPPRESS_HELP
from traceback import format_exc

import GeneAnnotation

from Utils import logger
from Utils.logger import critical, err, info, warn
from Utils.call_process import run
from Utils.bam_bed_utils import index_bam, prepare_beds, extract_gene_names_and_filter_exons, verify_bam, verify_bed
from Utils.file_utils import adjust_path, safe_mkdir, verify_file, remove_quotes, file_exists, which
from Utils.proc_args import read_samples, find_bams, find_fastq_pairs
from Utils import fai

import targqc
import targqc.config as tc
from targqc import Sample
from targqc.cov import make_targqc_reports
from targqc.fastq import align, downsample


options = [
    (['--bam'], dict(dest='bam', help='path to the BAM file to analyse',)),
    (['-1'], dict(dest='l_fpath', help='fastq left reads, optional instead of BAM')),
    (['-2'], dict(dest='r_fpath', help='fastq right reads, optional instead of BAM')),
    (['-s', '--sample', '--name'], dict(dest='sample', help='Sample name (default is part of name of the first parameter prior to the first - or .',)),
    (['--bed', '--capture', '--amplicons'], dict(dest='bed', help='BED file with regions to analyse. If not specified, CDS across full genome will be analysed',)),
    (['-o', '--output-dir'], dict(
        dest='output_dir',
        metavar='DIR',
        help='Output directory (or directory name in case of bcbio final dir)',
        default=os.getcwd(),
     )),
    (['--refseq-bed', '--exons', '--exome', '--features'], dict(
        dest='features',
        help='BED file with real CDS/Exon/Gene/Transcript regions with annotations, to override '
             'GeneAnnotation/RefSeq/RefSeq_CDS_miRNA.all_features.{genome}.canon.bed',
     )),
    (['-g', '--genome'], dict(
        dest='genome',
        help='Genome build (hg19 or hg38), used to pick genome annotation BED file if not specified',
    )),
    (['--bwa-prefix'], dict(
        dest='bwa_prefix',
        help='Path to BWA index prefix to align if input is fastq',
     )),
    (['--padding'], dict(
        dest='padding',
        type='int',
        help='integer indicating the number of bases to extend each target region up and down-stream. '
             'Default is ' + str(tc.padding),
        default=tc.padding
     )),
    (['--downsample-to'], dict(
        dest='downsample_to',
        type='int',
        help='If input is fastq, optionally downsample reads to this number',
        default=tc.downsample_to,
     )),
    (['--parallel'], dict(
        dest='parallel',
        help='Type of parallelization: ("threaded" or "sge")',
        default=tc.parallel
     )),
    (['-t', '--nt', '--threads'], dict(
        dest='threads',
        type='int',
        help='Number of threads',
        default=tc.threads
     )),
    (['--reuse'], dict(
        dest='reuse_intermediate',
        help='reuse intermediate non-empty files in the work dir from previous run',
        action='store_true',
        default=tc.reuse_intermediate
     )),

    ##############
    ## Extended: #
    (['--original-bed'], dict(
        dest='original_target_bed',
        help=SUPPRESS_HELP,
     )),
    (['--original-exons', '--original-features'], dict(
        dest='original_features_bed',
        help=SUPPRESS_HELP,  # original features genes bed file path (just for reporting)
     )),
    (['--features-no-genes', '--exons-no-genes'], dict(
        dest='features_no_genes',
        help=SUPPRESS_HELP,  # a BED file with real CDS/Exon regions with annotations, w/o Gene/Transcript records; provided if --no-prep-bed set
     )),
    (['--cds'], dict(
        dest='cds_bed_fpath',
        help=SUPPRESS_HELP,  # a BED file with real CDS regions in case if no --bed input provided, and if --no-prep-bed set
     )),
    (['--fai'], dict(
        dest='fai',
        help=SUPPRESS_HELP,  # Path to FAI file - to sort BAM and BED files, and to get chromosome lengths for proper padding BED files; optional
     )),
    # (['--reannotate'], dict(
    #     dest='reannotate',
    #     help='re-annotate BED file with gene names',
    #     action='store_true',
    #     default=True)
    #  ),
    (['-e', '--extended'], dict(
        dest='extended',
        action='store_true',
        default=False,
        help=SUPPRESS_HELP,  # 'extended - flagged regions and missed variants',
     )),
    (['--no-dedup'], dict(
        dest='no_dedup',
        action='store_true',
        help=SUPPRESS_HELP,
        default=not tc.dedup,
     )),
    (['--debug'], dict(
        dest='debug',
        action='store_true',
        default=tc.debug,
        help=SUPPRESS_HELP,
     )),
    (['--work-dir'], dict(dest='work_dir', metavar='DIR', help=SUPPRESS_HELP)),
    (['--log-dir'], dict(dest='log_dir', metavar='DIR', help=SUPPRESS_HELP)),
    # (['--project-name'], dict(dest='project_name', help=SUPPRESS_HELP)),
    (['--email'], dict(dest='email', help=SUPPRESS_HELP)),
]


def main(args):
    output_dir, work_dir, bam_by_sample, fastqs_by_sample, target_bed = process_opts()

    samples = []
    for sname, (l, r) in fastqs_by_sample.items():
        s = Sample(sname, join(output_dir, sname))
        s.l_fpath = l
        s.r_fpath = r
        samples.append(s)
    for sname, bam_fpath in bam_by_sample.items():
        s = Sample(sname, join(output_dir, sname), bam=bam_fpath)
        samples.append(s)

    samples.sort(key=lambda _s: _s.key_to_sort())

    gene_keys_list = None
    if not tc.features_no_genes_bed:
        info()
        info('-' * 70)
        info('Preparing the BED file')
        tc.features_bed_fpath, tc.features_no_genes_bed, target_bed, seq2c_bed = prepare_beds(
            work_dir, tc.fai_fpath, tc.features_bed_fpath, target_bed, tc.cds_bed_fpath, reuse=tc.reuse_intermediate)

        tc.original_target_bed = tc.features_bed_fpath
        gene_keys_set, gene_keys_list, target_bed, tc.features_bed_fpath, tc.features_no_genes_bed = \
            extract_gene_names_and_filter_exons(work_dir, target_bed, tc.features_bed_fpath, tc.features_no_genes_bed,
                                                reuse=tc.reuse_intermediate)
    else:
        info('The BED file is ready, skipping preparing.')
        gene_keys_set, gene_keys_list, _, _, _ = extract_gene_names_and_filter_exons(
            work_dir, target_bed, tc.features_bed_fpath, tc.features_no_genes_bed, reuse=tc.reuse_intermediate)
    info('-' * 70)

    threads_one_sample = max(1, tc.threads / len(samples))
    for sample in samples:
        info()
        info('Processing ' + sample.name)
        summary_report, gene_report = proc_one_sample(work_dir, sample, target_bed, gene_keys_list)

        info('')
        info('*' * 70)
        if summary_report.txt_fpath and verify_file(summary_report.txt_fpath):
            info('Summary report: ' + summary_report.txt_fpath)
        if gene_report:
            if gene_report.txt_fpath and verify_file(gene_report.txt_fpath):
                info('All regions: ' + gene_report.txt_fpath + ' (' + str(len(gene_report.rows)) + ' regions)')
        info('')
        info('*' * 70)

    if not tc.debug and work_dir and isdir(work_dir):
        shutil.rmtree(work_dir)


def proc_one_sample(work_dir, sample, bed_fpath, gene_keys_list):
    if not sample.bam and sample.l_fpath and sample.r_fpath:
        sample.bam = proc_fastq(
            sample.name, verify_file(sample.l_fpath), verify_file(sample.r_fpath),
            tc.bwa_prefix, tc.downsample_to, tc.dedup)

    info('Using alignment ' + sample.bam)

    index_bam(sample.bam)

    # picard_ins_size_hist(cnf, sample, bam_fpath, output_dir)
    avg_depth, gene_by_name_and_chrom, reports = make_targqc_reports(
        work_dir, sample, bed_fpath, gene_keys_list)

    # #if cnf.extended:
    # try:
    #     info('Generating flagged regions report...')
    #     flagged_report = generate_flagged_regions_report(cnf, cnf.output_dir, sample, avg_depth, gene_by_name_and_chrom)
    #     if not flagged_report:
    #         err('Flagged regions report was not generated')
    #         err()
    # except:
    #     err(format_exc())

    return reports


def set_up_dirs(output_dir=None, work_dir=None, log_dir=None):
    """ Creates output_dir, work_dir; sets up log
    """
    output_dir = adjust_path(output_dir or join(os.getcwd(), targqc.targqc_name))
    safe_mkdir(output_dir, 'output_dir')
    info('Saving results into ' + output_dir)

    work_dir = set_up_work_dir(output_dir, work_dir=work_dir)
    set_up_log(log_dir or output_dir)

    return output_dir, work_dir


def set_up_work_dir(output_dir, work_dir=None):
    if not work_dir:
        work_dir_name = 'work'
        work_dir = join(output_dir, work_dir_name)
    safe_mkdir(work_dir, 'working directory')
    tc.work_dir = work_dir
    return work_dir


def set_up_log(log_dir):
    log_fname = targqc.targqc_name + '.log'
    log_fpath = join(log_dir, log_fname)

    if file_exists(log_fpath):
        timestamp = datetime.datetime.fromtimestamp(os.stat(log_fpath).st_mtime)
        mv_log_fpath = log_fpath + '.' + timestamp.strftime("%Y-%m-%d_%H-%M-%S")
        try:
            if isfile(mv_log_fpath):
                os.remove(mv_log_fpath)
            if not isfile(mv_log_fpath):
                os.rename(log_fpath, mv_log_fpath)
        except OSError:
            pass
    info('log_fpath: ' + log_fpath)
    info()


def process_opts():
    parser = OptionParser()
    for args, kwargs in options:
        parser.add_option(*args, **kwargs)
    opts, args = parser.parse_args()

    tc.debug = logger.is_debug = opts.debug
    tc.parallel = opts.parallel
    tc.threads = opts.threads
    tc.reuse_intermediate = opts.reuse_intermediate

    bam_by_sample = dict()
    fastqs_by_sample = dict()

    if opts.bam or opts.l_fpath:
        if opts.sample_name:
            sample_name = remove_quotes(opts.sample_name)
            if opts.bam:
                bam_by_sample[sample_name] = verify_bam(opts.bam, is_critical=True)
            elif opts.l_fpath:
                l_fpath = verify_bam(opts.l_fpath, is_critical=True)
                r_fpath = verify_bam(opts.l_fpath)
                fastqs_by_sample[sample_name] = l_fpath, r_fpath
        else:
            if opts.bam:
                bam_by_sample = find_bams(opts.bam)
            elif opts.l_fpath:
                fastqs_by_sample = find_fastq_pairs([opts.l_fpath, opts.r_fpath])
    else:
        fastqs_by_sample, bam_by_sample = read_samples(args)

    if fastqs_by_sample:
        if not opts.bwa_prefix:
            critical('--bwa-prefix is required when running from fastq')
        tc.bwa_prefix = verify_file(opts.bwa_prefix, is_critical=True)

    output_dir, work_dir = set_up_dirs(opts.output_dir, opts.work_dir, opts.log_dir)
    info(' '.join(sys.argv))
    info()

    tc.downsample_to = opts.downsample_to
    tc.padding = opts.padding
    tc.genome = opts.genome
    tc.dedup = not opts.no_dedup

    if opts.features:
        tc.features_bed_fpath = verify_bed(opts.features, is_critical=True)
        tc.cds_bed_fpath = verify_bed(opts.cds_bed_fpath, is_critical=True)
    elif tc.genome:
        tc.features_bed_fpath = verify_file(join(dirname(GeneAnnotation.__file__), GeneAnnotation.ANNOTATION.format(genome=tc.genome)))
        tc.cds_bed_fpath = verify_file(join(dirname(GeneAnnotation.__file__), GeneAnnotation.CDS.format(genome=tc.genome)))
        if not tc.features_bed_fpath or not tc.cds_bed_fpath:
            critical('Genome ' + tc.genome + ' is not supported. Supported: ' + ', '.join(GeneAnnotation.SUPPORTED_GENOMES))
    else:
        warn('Neither --refseq-bed nor --genome is specified, analysing without genomic features.')
    if opts.features_no_genes:
        tc.features_no_genes_bed = verify_bed(opts.features_no_genes, is_critical=True)
    tc.original_target_bed = opts.original_target_bed

    bed_fpath = None
    if opts.bed:
        bed_fpath = verify_file(opts.bed, is_critical=True)
        info('Using amplicons/capture panel ' + bed_fpath)
    elif tc.features_bed_fpath:
        info('No BED on input; analysing CDS as target')

    if opts.fai:
        tc.fai_fpath = opts.fai
    elif tc.genome:
        tc.fai_fpath = verify_file(join(dirname(fai.__file__), fai.FAI.format(genome=tc.genome)))
        if not tc.fai_fpath:
            critical('Genome ' + tc.genome + ' is not supported. Supported: ' + ', '.join(fai.SUPPORTED_GENOMES))
    else:
        err('Cannot analyse BED files without --fai or --genome specified')

    return output_dir, work_dir, bam_by_sample, fastqs_by_sample, bed_fpath


def proc_fastq(work_dir, sample_name, l_fpath, r_fpath, bwa_prefix, downsample_to, dedup=True):
    if downsample_to:
        info('Downsampling the reads to ' + str(downsample_to))
        l_fpath, r_fpath = downsample(work_dir, sample_name, work_dir, l_fpath, r_fpath, downsample_to, suffix='subset')

    sambamba = which('sambamba')
    bwa = which('bwa')
    seqtk = which('seqtk')
    samblaster = which('samblaster')
    if not (sambamba and bwa and seqtk and samblaster):
        critical('sambamba, BWA, seqtk and samblaster are required to align BAM')
    info()
    info('Aligning reads to the reference')
    bam_fpath = align(work_dir, sample_name, l_fpath, r_fpath, sambamba, bwa, seqtk, samblaster, bwa_prefix, dedup)
    bam_fpath = verify_bam(bam_fpath)
    if not bam_fpath:
        critical('Sample ' + sample_name + ' was not aligned successfully.')
    return bam_fpath


# def picard_ins_size_hist(cnf, sample, bam_fpath, output_dir):
#     picard = get_system_path(cnf, 'java', 'picard')
#     if picard:
#         safe_mkdir(dirname(sample.picard_ins_size_hist_txt_fpath))
#         safe_mkdir(dirname(sample.picard_ins_size_hist_pdf_fpath))
#         info('Picard ins size hist for "' + basename(bam_fpath) + '"')
#         cmdline = '{picard} CollectInsertSizeMetrics' \
#                   ' I={bam_fpath}' \
#                   ' O={sample.picard_ins_size_hist_txt_fpath}' \
#                   ' H={sample.picard_ins_size_hist_pdf_fpath}' \
#                   ' VALIDATION_STRINGENCY=LENIENT'
#
#         cmdline = cmdline.format(**locals())
#         call(cnf, cmdline, output_fpath=sample.picard_ins_size_hist_txt_fpath,
#              stdout_to_outputfile=False, exit_on_error=False)


if __name__ == '__main__':
    main(sys.argv)


